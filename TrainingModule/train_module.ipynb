{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "203010d6",
   "metadata": {},
   "source": [
    "## Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "id": "95adbe32",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-16T14:50:33.686267Z",
     "start_time": "2025-01-16T14:50:28.522797Z"
    }
   },
   "source": [
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import balanced_accuracy_score, f1_score, accuracy_score\n",
    "from sklearn.model_selection import PredefinedSplit\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from skopt import BayesSearchCV\n",
    "\n",
    "save_in_test_folder = True\n",
    "if save_in_test_folder:\n",
    "    filepath = \"../TestModule\"\n",
    "else:\n",
    "    filepath = \".\"\n",
    "\n",
    "seed = 42\n",
    "FILENAME = \"dataset/train_dataset.csv\"\n",
    "\n",
    "#Prepare train data\n",
    "df1 = pd.read_csv(FILENAME, sep=\",\", low_memory=False)\n",
    "\n",
    "# get features names\n",
    "features = list(df1.columns)\n",
    "features_to_remove = [\"label\", \"ts\", \"src_ip\", \"dst_ip\", \"dns_query\", \"ssl_subject\", \"ssl_issuer\", \"http_uri\", \"type\", \"http_referrer\", \"http_user_agent\"]\n",
    "features = [feature for feature in features if feature not in features_to_remove]\n",
    "df1 = df1[features + [\"type\"]]\n",
    "\n",
    "# Converte i valori in numeri, sostituendo quelli non validi con NaN\n",
    "df1[\"src_bytes\"] = pd.to_numeric(df1[\"src_bytes\"], errors='coerce')\n",
    "# Filtra le righe con NaN (valori non convertibili)\n",
    "df1 = df1.dropna(subset=[\"src_bytes\"])\n",
    "# Converte i valori rimasti in interi\n",
    "df1.loc[:, \"src_bytes\"] = df1[\"src_bytes\"].astype(int)\n",
    "\n",
    "print(\"#Righe: \" + str(df1.shape[0]) + \" #Colonne: \" + str(df1.shape[1]))\n",
    "df1 = df1.dropna()\n",
    "print(\"#Righe: \" + str(df1.shape[0]) + \" #Colonne: \" + str(df1.shape[1]))\n",
    "\n",
    "X = df1[features]\n",
    "y = df1[\"type\"]\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(y)\n",
    "with open(f\"{filepath}/transformer/target_encoder.save\", \"wb\") as f:\n",
    "    pickle.dump(le, f)\n",
    "\n",
    "y = le.transform(y)\n",
    "\n",
    "indices = np.arange(X.shape[0])\n",
    "train_idx, val_idx = train_test_split(indices, test_size=0.2, stratify=y, random_state=seed)\n",
    "\n",
    "# fold = np.zeros(X.shape[0])\n",
    "# fold[train_idx] = -1\n",
    "\n",
    "n_splits = 10\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "fold = np.full(len(y), -1)  # Inizializza tutto con -1 (default: train)\n",
    "\n",
    "# Assegna i fold ai campioni\n",
    "for fold_number, (train_idx, val_idx) in enumerate(skf.split(X, y)):\n",
    "    fold[val_idx] = fold_number  # Assegna il numero del fold ai campioni di validazione\n",
    "\n",
    "ps = PredefinedSplit(fold)\n",
    "ps.get_n_splits()\n",
    "\n",
    "# for i, (train_index, test_index) in enumerate(ps.split()):\n",
    "#     print(f\"Fold {i}:\")\n",
    "#     print(f\"  Train: index={train_index}\")\n",
    "#     print(f\"  Test:  index={test_index}\")\n",
    "\n",
    "# take only x with index in val_idx\n",
    "X_val = X.iloc[val_idx]\n",
    "y_val = y[val_idx]\n",
    "X_train = X.iloc[train_idx]\n",
    "y_train = y[train_idx]"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Righe: 616983 #Colonne: 36\n",
      "#Righe: 616983 #Colonne: 36\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "1c5bc153025b9757",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T15:40:25.474358Z",
     "start_time": "2025-01-14T15:40:25.192162Z"
    }
   },
   "source": [
    "df1"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        src_port  dst_port proto service   duration  src_bytes  dst_bytes  \\\n",
       "0          53972     10502   tcp       -   0.000000        0.0          0   \n",
       "1          37513        53   udp     dns   0.163608       47.0        423   \n",
       "2           2077      2077   tcp       -   0.208218        0.0          0   \n",
       "3          53972     10502   tcp       -   0.000000        0.0          0   \n",
       "4           1880     47979   tcp       -   0.000000        0.0          0   \n",
       "...          ...       ...   ...     ...        ...        ...        ...   \n",
       "616997     53116        53   udp     dns   0.044893       84.0        424   \n",
       "616998     57669        53   udp     dns   0.002957       84.0        436   \n",
       "616999     54730        53   udp     dns   0.016624       58.0        178   \n",
       "617000     59846       443   tcp     ssl  48.271568     3219.0       1212   \n",
       "617001     56698        53   udp     dns   2.440571       68.0        156   \n",
       "\n",
       "       conn_state  missed_bytes  src_pkts  ...  http_version  \\\n",
       "0             OTH             0         0  ...             -   \n",
       "1              SF             0         1  ...             -   \n",
       "2              S0             0       120  ...             -   \n",
       "3             OTH             0         0  ...             -   \n",
       "4             OTH             0         1  ...             -   \n",
       "...           ...           ...       ...  ...           ...   \n",
       "616997         SF             0         2  ...             -   \n",
       "616998         SF             0         2  ...             -   \n",
       "616999         SF             0         2  ...             -   \n",
       "617000         SF             0        26  ...             -   \n",
       "617001         SF             0         2  ...             -   \n",
       "\n",
       "        http_request_body_len  http_response_body_len  http_status_code  \\\n",
       "0                           0                       0                 0   \n",
       "1                           0                       0                 0   \n",
       "2                           0                       0                 0   \n",
       "3                           0                       0                 0   \n",
       "4                           0                       0                 0   \n",
       "...                       ...                     ...               ...   \n",
       "616997                      0                       0                 0   \n",
       "616998                      0                       0                 0   \n",
       "616999                      0                       0                 0   \n",
       "617000                      0                       0                 0   \n",
       "617001                      0                       0                 0   \n",
       "\n",
       "        http_orig_mime_types  http_resp_mime_types weird_name weird_addl  \\\n",
       "0                          -                     -          -          -   \n",
       "1                          -                     -          -          -   \n",
       "2                          -                     -          -          -   \n",
       "3                          -                     -          -          -   \n",
       "4                          -                     -          -          -   \n",
       "...                      ...                   ...        ...        ...   \n",
       "616997                     -                     -          -          -   \n",
       "616998                     -                     -          -          -   \n",
       "616999                     -                     -          -          -   \n",
       "617000                     -                     -          -          -   \n",
       "617001                     -                     -          -          -   \n",
       "\n",
       "       weird_notice    type  \n",
       "0                 -  normal  \n",
       "1                 -  normal  \n",
       "2                 -  normal  \n",
       "3                 -  normal  \n",
       "4                 -  normal  \n",
       "...             ...     ...  \n",
       "616997            -    mitm  \n",
       "616998            -    mitm  \n",
       "616999            -    mitm  \n",
       "617000            -    mitm  \n",
       "617001            -    mitm  \n",
       "\n",
       "[616983 rows x 36 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>src_port</th>\n",
       "      <th>dst_port</th>\n",
       "      <th>proto</th>\n",
       "      <th>service</th>\n",
       "      <th>duration</th>\n",
       "      <th>src_bytes</th>\n",
       "      <th>dst_bytes</th>\n",
       "      <th>conn_state</th>\n",
       "      <th>missed_bytes</th>\n",
       "      <th>src_pkts</th>\n",
       "      <th>...</th>\n",
       "      <th>http_version</th>\n",
       "      <th>http_request_body_len</th>\n",
       "      <th>http_response_body_len</th>\n",
       "      <th>http_status_code</th>\n",
       "      <th>http_orig_mime_types</th>\n",
       "      <th>http_resp_mime_types</th>\n",
       "      <th>weird_name</th>\n",
       "      <th>weird_addl</th>\n",
       "      <th>weird_notice</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>53972</td>\n",
       "      <td>10502</td>\n",
       "      <td>tcp</td>\n",
       "      <td>-</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>OTH</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37513</td>\n",
       "      <td>53</td>\n",
       "      <td>udp</td>\n",
       "      <td>dns</td>\n",
       "      <td>0.163608</td>\n",
       "      <td>47.0</td>\n",
       "      <td>423</td>\n",
       "      <td>SF</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2077</td>\n",
       "      <td>2077</td>\n",
       "      <td>tcp</td>\n",
       "      <td>-</td>\n",
       "      <td>0.208218</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>S0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>...</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53972</td>\n",
       "      <td>10502</td>\n",
       "      <td>tcp</td>\n",
       "      <td>-</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>OTH</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1880</td>\n",
       "      <td>47979</td>\n",
       "      <td>tcp</td>\n",
       "      <td>-</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>OTH</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>616997</th>\n",
       "      <td>53116</td>\n",
       "      <td>53</td>\n",
       "      <td>udp</td>\n",
       "      <td>dns</td>\n",
       "      <td>0.044893</td>\n",
       "      <td>84.0</td>\n",
       "      <td>424</td>\n",
       "      <td>SF</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>mitm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>616998</th>\n",
       "      <td>57669</td>\n",
       "      <td>53</td>\n",
       "      <td>udp</td>\n",
       "      <td>dns</td>\n",
       "      <td>0.002957</td>\n",
       "      <td>84.0</td>\n",
       "      <td>436</td>\n",
       "      <td>SF</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>mitm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>616999</th>\n",
       "      <td>54730</td>\n",
       "      <td>53</td>\n",
       "      <td>udp</td>\n",
       "      <td>dns</td>\n",
       "      <td>0.016624</td>\n",
       "      <td>58.0</td>\n",
       "      <td>178</td>\n",
       "      <td>SF</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>mitm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617000</th>\n",
       "      <td>59846</td>\n",
       "      <td>443</td>\n",
       "      <td>tcp</td>\n",
       "      <td>ssl</td>\n",
       "      <td>48.271568</td>\n",
       "      <td>3219.0</td>\n",
       "      <td>1212</td>\n",
       "      <td>SF</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>...</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>mitm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617001</th>\n",
       "      <td>56698</td>\n",
       "      <td>53</td>\n",
       "      <td>udp</td>\n",
       "      <td>dns</td>\n",
       "      <td>2.440571</td>\n",
       "      <td>68.0</td>\n",
       "      <td>156</td>\n",
       "      <td>SF</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>mitm</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>616983 rows × 36 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "id": "7d5cee74",
   "metadata": {},
   "source": [
    "## Preprocess the dataset"
   ]
  },
  {
   "cell_type": "code",
   "id": "adbe4df5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-16T14:50:40.949649Z",
     "start_time": "2025-01-16T14:50:34.464470Z"
    }
   },
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import OrdinalEncoder, RobustScaler, OneHotEncoder\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "import pickle\n",
    "\n",
    "categorical_columns = X_train.select_dtypes(include=[\"object\"]).columns.tolist()\n",
    "numeric_columns = X_train.select_dtypes(include=[\"int64\", \"float64\"]).columns.tolist()\n",
    "# boolean_columns = X_train.select_dtypes(include=[\"bool\"]).columns.tolist()\n",
    "\n",
    "ct = ColumnTransformer(\n",
    "    [\n",
    "        # (\"cat\", OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1), categorical_columns),  # Trasforma le colonne categoriche\n",
    "        (\"cat\", OneHotEncoder(handle_unknown='infrequent_if_exist', sparse_output=False), categorical_columns),  # Trasforma le colonne categoriche\n",
    "        (\"scale\", RobustScaler(), numeric_columns)  # Normalizza le colonne numeriche\n",
    "    ],\n",
    "    remainder=\"passthrough\"  # Mantieni le altre colonne invariate\n",
    ")\n",
    "ct.set_output(transform=\"pandas\")\n",
    "\n",
    "ct = ct.fit(X_train)\n",
    "with open(f\"{filepath}/transformer/transformer.save\", \"wb\") as f:\n",
    "    pickle.dump(ct, f)\n",
    "\n",
    "# train set\n",
    "X_train = ct.transform(X_train)\n",
    "\n",
    "# validation set\n",
    "X_val = ct.transform(X_val)\n",
    "\n",
    "# X\n",
    "# X = ct.transform(X)"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Feature selection",
   "id": "d23674e692573e9b"
  },
  {
   "cell_type": "code",
   "id": "988857df",
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-01-16T14:54:39.191102Z"
    }
   },
   "source": [
    "rf = RandomForestClassifier(n_estimators=3, random_state=seed)\n",
    "sfs = SequentialFeatureSelector(estimator=rf, direction=\"backward\", n_features_to_select=\"auto\", scoring=\"balanced_accuracy\", n_jobs=12)\n",
    "\n",
    "sfs.fit(X_train, y_train)\n",
    "with open(f\"{filepath}/transformer/sfs.save\", \"wb\") as f:\n",
    "    pickle.dump(sfs, f)\n",
    "\n",
    "with open(\"../TestModule/transformer/sfs.save\", \"rb\") as f:\n",
    "    sfs: SequentialFeatureSelector = pickle.load(f)\n",
    "\n",
    "# train set\n",
    "X_train = sfs.transform(X_train)\n",
    "\n",
    "# validation set\n",
    "X_val = sfs.transform(X_val)\n",
    "\n",
    "# X\n",
    "columns_to_keep = [column.split(\"__\")[1].split(\"_\")[0] for column in sfs.get_feature_names_out()]\n",
    "X = X[columns_to_keep]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "261bb308",
   "metadata": {},
   "source": [
    "## Apply K-Nearest Neighbour"
   ]
  },
  {
   "cell_type": "code",
   "id": "1a123521",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-16T14:52:39.269279800Z",
     "start_time": "2025-01-16T11:53:16.257718Z"
    }
   },
   "source": [
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import os\n",
    "\n",
    "os.environ['OMP_NUM_THREADS'] = '12'\n",
    "\n",
    "# param_grid = {\n",
    "#     'n_neighbors': [3, 5, 7, 9, 11],  # Number of neighbors to consider\n",
    "#     'weights': ['uniform', 'distance'],  # Weight function\n",
    "#     'metric': ['euclidean', 'manhattan', 'minkowski'],  # Distance metrics\n",
    "#     'p': [1, 2],  # Minkowski parameter (1 for Manhattan, 2 for Euclidean)\n",
    "#     'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],  # Algorithm to compute neighbors\n",
    "#     'leaf_size': [30, 50, 70, 90, 100]\n",
    "# }\n",
    "param_grid = {\n",
    "    'knn__n_neighbors': [3, 5, 7, 9, 11],  # Number of neighbors to consider\n",
    "    'knn__weights': ['uniform', 'distance'],  # Weight function\n",
    "    'knn__metric': ['euclidean', 'manhattan', 'minkowski'],  # Distance metrics\n",
    "    'knn__p': [1, 2],  # Minkowski parameter (1 for Manhattan, 2 for Euclidean)\n",
    "    'knn__algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],  # Algorithm to compute neighbors\n",
    "    'knn__leaf_size': [30, 50, 70, 90, 100]\n",
    "}\n",
    "\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        ('ct', ColumnTransformer(\n",
    "            [\n",
    "                # (\"cat\", OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1), categorical_columns),  # Trasforma le colonne categoriche\n",
    "                (\"cat\", OneHotEncoder(handle_unknown='infrequent_if_exist', sparse_output=False), categorical_columns),  # Trasforma le colonne categoriche\n",
    "                (\"scale\", RobustScaler(), numeric_columns)  # Normalizza le colonne numeriche\n",
    "            ],\n",
    "            remainder=\"passthrough\"  # Mantieni le altre colonne invariate\n",
    "        )),\n",
    "        ('knn', KNeighborsClassifier())\n",
    "    ],\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "grid = RandomizedSearchCV(pipeline, param_grid, cv=ps, n_iter=10, random_state=seed, n_jobs=12, verbose=2, scoring=\"balanced_accuracy\")\n",
    "grid.fit(X, y)\n",
    "\n",
    "print(\"Best parameters:\", grid.best_params_)\n",
    "print(\"Best score:\", grid.best_score_)\n",
    "best_knn = grid.best_estimator_\n",
    "with open(f\"{filepath}/models/knn.save\", \"wb\") as file:\n",
    "    pickle.dump(best_knn, file)\n",
    "\n",
    "y_pred = best_knn.predict(X_val)\n",
    "print(\"Accuracy:\", accuracy_score(y_val, y_pred))\n",
    "print(\"Balanced accuracy:\", balanced_accuracy_score(y_val, y_pred))\n",
    "print(\"F1 score:\", f1_score(y_val, y_pred, average=\"weighted\"))\n",
    "pd.DataFrame(grid.cv_results_)\n",
    "\n",
    "# Accuracy: 0.9745696781095011\n",
    "# Balanced\n",
    "# accuracy: 0.8729493259671391\n",
    "# F1\n",
    "# score: 0.9743348139040916\n",
    "# knn = KNeighborsClassifier(n_jobs=12).fit(X_train, y_train)\n",
    "# y_pred = knn.predict(X_val)\n",
    "# print(\"Accuracy:\", accuracy_score(y_val, y_pred))\n",
    "# print(\"Balanced accuracy:\", balanced_accuracy_score(y_val, y_pred))\n",
    "# print(\"F1 score:\", f1_score(y_val, y_pred, average=\"weighted\"))\n",
    "# with open(f\"{filepath}/models/knn2.save\", \"wb\") as file:\n",
    "#     pickle.dump(knn, file)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "\nAll the 100 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n100 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\miaob\\PycharmProjects\\DataAnalyticsProject\\Lib\\site-packages\\pandas\\core\\indexes\\base.py\", line 3805, in get_loc\n    return self._engine.get_loc(casted_key)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"index.pyx\", line 167, in pandas._libs.index.IndexEngine.get_loc\n  File \"index.pyx\", line 196, in pandas._libs.index.IndexEngine.get_loc\n  File \"pandas\\\\_libs\\\\hashtable_class_helper.pxi\", line 7081, in pandas._libs.hashtable.PyObjectHashTable.get_item\n  File \"pandas\\\\_libs\\\\hashtable_class_helper.pxi\", line 7089, in pandas._libs.hashtable.PyObjectHashTable.get_item\nKeyError: 'proto'\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"C:\\Users\\miaob\\PycharmProjects\\DataAnalyticsProject\\Lib\\site-packages\\sklearn\\utils\\_indexing.py\", line 364, in _get_column_indices\n    col_idx = all_columns.get_loc(col)\n              ^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\miaob\\PycharmProjects\\DataAnalyticsProject\\Lib\\site-packages\\pandas\\core\\indexes\\base.py\", line 3812, in get_loc\n    raise KeyError(key) from err\nKeyError: 'proto'\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"C:\\Users\\miaob\\PycharmProjects\\DataAnalyticsProject\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\miaob\\PycharmProjects\\DataAnalyticsProject\\Lib\\site-packages\\sklearn\\base.py\", line 1389, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\miaob\\PycharmProjects\\DataAnalyticsProject\\Lib\\site-packages\\sklearn\\pipeline.py\", line 652, in fit\n    Xt = self._fit(X, y, routed_params, raw_params=params)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\miaob\\PycharmProjects\\DataAnalyticsProject\\Lib\\site-packages\\sklearn\\pipeline.py\", line 586, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\miaob\\PycharmProjects\\DataAnalyticsProject\\Lib\\site-packages\\joblib\\memory.py\", line 312, in __call__\n    return self.func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\miaob\\PycharmProjects\\DataAnalyticsProject\\Lib\\site-packages\\sklearn\\pipeline.py\", line 1540, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\miaob\\PycharmProjects\\DataAnalyticsProject\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 319, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\miaob\\PycharmProjects\\DataAnalyticsProject\\Lib\\site-packages\\sklearn\\base.py\", line 1389, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\miaob\\PycharmProjects\\DataAnalyticsProject\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py\", line 992, in fit_transform\n    self._validate_column_callables(X)\n  File \"C:\\Users\\miaob\\PycharmProjects\\DataAnalyticsProject\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py\", line 551, in _validate_column_callables\n    transformer_to_input_indices[name] = _get_column_indices(X, columns)\n                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\miaob\\PycharmProjects\\DataAnalyticsProject\\Lib\\site-packages\\sklearn\\utils\\_indexing.py\", line 372, in _get_column_indices\n    raise ValueError(\"A given column is not a column of the dataframe\") from e\nValueError: A given column is not a column of the dataframe\n",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[9], line 40\u001B[0m\n\u001B[0;32m     25\u001B[0m pipeline \u001B[38;5;241m=\u001B[39m Pipeline(\n\u001B[0;32m     26\u001B[0m     [\n\u001B[0;32m     27\u001B[0m         (\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mct\u001B[39m\u001B[38;5;124m'\u001B[39m, ColumnTransformer(\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     36\u001B[0m     verbose\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m     37\u001B[0m )\n\u001B[0;32m     39\u001B[0m grid \u001B[38;5;241m=\u001B[39m RandomizedSearchCV(pipeline, param_grid, cv\u001B[38;5;241m=\u001B[39mps, n_iter\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m10\u001B[39m, random_state\u001B[38;5;241m=\u001B[39mseed, n_jobs\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m12\u001B[39m, verbose\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m, scoring\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbalanced_accuracy\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m---> 40\u001B[0m \u001B[43mgrid\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     42\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mBest parameters:\u001B[39m\u001B[38;5;124m\"\u001B[39m, grid\u001B[38;5;241m.\u001B[39mbest_params_)\n\u001B[0;32m     43\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mBest score:\u001B[39m\u001B[38;5;124m\"\u001B[39m, grid\u001B[38;5;241m.\u001B[39mbest_score_)\n",
      "File \u001B[1;32m~\\PycharmProjects\\DataAnalyticsProject\\Lib\\site-packages\\sklearn\\base.py:1389\u001B[0m, in \u001B[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001B[1;34m(estimator, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1382\u001B[0m     estimator\u001B[38;5;241m.\u001B[39m_validate_params()\n\u001B[0;32m   1384\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[0;32m   1385\u001B[0m     skip_parameter_validation\u001B[38;5;241m=\u001B[39m(\n\u001B[0;32m   1386\u001B[0m         prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[0;32m   1387\u001B[0m     )\n\u001B[0;32m   1388\u001B[0m ):\n\u001B[1;32m-> 1389\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfit_method\u001B[49m\u001B[43m(\u001B[49m\u001B[43mestimator\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\PycharmProjects\\DataAnalyticsProject\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1023\u001B[0m, in \u001B[0;36mBaseSearchCV.fit\u001B[1;34m(self, X, y, **params)\u001B[0m\n\u001B[0;32m   1017\u001B[0m     results \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_format_results(\n\u001B[0;32m   1018\u001B[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001B[0;32m   1019\u001B[0m     )\n\u001B[0;32m   1021\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m results\n\u001B[1;32m-> 1023\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_run_search\u001B[49m\u001B[43m(\u001B[49m\u001B[43mevaluate_candidates\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1025\u001B[0m \u001B[38;5;66;03m# multimetric is determined here because in the case of a callable\u001B[39;00m\n\u001B[0;32m   1026\u001B[0m \u001B[38;5;66;03m# self.scoring the return type is only known after calling\u001B[39;00m\n\u001B[0;32m   1027\u001B[0m first_test_score \u001B[38;5;241m=\u001B[39m all_out[\u001B[38;5;241m0\u001B[39m][\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtest_scores\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n",
      "File \u001B[1;32m~\\PycharmProjects\\DataAnalyticsProject\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1950\u001B[0m, in \u001B[0;36mRandomizedSearchCV._run_search\u001B[1;34m(self, evaluate_candidates)\u001B[0m\n\u001B[0;32m   1948\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21m_run_search\u001B[39m(\u001B[38;5;28mself\u001B[39m, evaluate_candidates):\n\u001B[0;32m   1949\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001B[39;00m\n\u001B[1;32m-> 1950\u001B[0m     \u001B[43mevaluate_candidates\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1951\u001B[0m \u001B[43m        \u001B[49m\u001B[43mParameterSampler\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1952\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mparam_distributions\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mn_iter\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrandom_state\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrandom_state\u001B[49m\n\u001B[0;32m   1953\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1954\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\PycharmProjects\\DataAnalyticsProject\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1000\u001B[0m, in \u001B[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001B[1;34m(candidate_params, cv, more_results)\u001B[0m\n\u001B[0;32m    993\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(out) \u001B[38;5;241m!=\u001B[39m n_candidates \u001B[38;5;241m*\u001B[39m n_splits:\n\u001B[0;32m    994\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    995\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcv.split and cv.get_n_splits returned \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    996\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124minconsistent results. Expected \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    997\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msplits, got \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(n_splits, \u001B[38;5;28mlen\u001B[39m(out) \u001B[38;5;241m/\u001B[39m\u001B[38;5;241m/\u001B[39m n_candidates)\n\u001B[0;32m    998\u001B[0m     )\n\u001B[1;32m-> 1000\u001B[0m \u001B[43m_warn_or_raise_about_fit_failures\u001B[49m\u001B[43m(\u001B[49m\u001B[43mout\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43merror_score\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1002\u001B[0m \u001B[38;5;66;03m# For callable self.scoring, the return type is only know after\u001B[39;00m\n\u001B[0;32m   1003\u001B[0m \u001B[38;5;66;03m# calling. If the return type is a dictionary, the error scores\u001B[39;00m\n\u001B[0;32m   1004\u001B[0m \u001B[38;5;66;03m# can now be inserted with the correct key. The type checking\u001B[39;00m\n\u001B[0;32m   1005\u001B[0m \u001B[38;5;66;03m# of out will be done in `_insert_error_scores`.\u001B[39;00m\n\u001B[0;32m   1006\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mcallable\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mscoring):\n",
      "File \u001B[1;32m~\\PycharmProjects\\DataAnalyticsProject\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:517\u001B[0m, in \u001B[0;36m_warn_or_raise_about_fit_failures\u001B[1;34m(results, error_score)\u001B[0m\n\u001B[0;32m    510\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m num_failed_fits \u001B[38;5;241m==\u001B[39m num_fits:\n\u001B[0;32m    511\u001B[0m     all_fits_failed_message \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m    512\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124mAll the \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mnum_fits\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m fits failed.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    513\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mIt is very likely that your model is misconfigured.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    514\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mYou can try to debug the error by setting error_score=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mraise\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    515\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mBelow are more details about the failures:\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m{\u001B[39;00mfit_errors_summary\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    516\u001B[0m     )\n\u001B[1;32m--> 517\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(all_fits_failed_message)\n\u001B[0;32m    519\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    520\u001B[0m     some_fits_failed_message \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m    521\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m{\u001B[39;00mnum_failed_fits\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m fits failed out of a total of \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mnum_fits\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    522\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThe score on these train-test partitions for these parameters\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    526\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mBelow are more details about the failures:\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m{\u001B[39;00mfit_errors_summary\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    527\u001B[0m     )\n",
      "\u001B[1;31mValueError\u001B[0m: \nAll the 100 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n100 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\miaob\\PycharmProjects\\DataAnalyticsProject\\Lib\\site-packages\\pandas\\core\\indexes\\base.py\", line 3805, in get_loc\n    return self._engine.get_loc(casted_key)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"index.pyx\", line 167, in pandas._libs.index.IndexEngine.get_loc\n  File \"index.pyx\", line 196, in pandas._libs.index.IndexEngine.get_loc\n  File \"pandas\\\\_libs\\\\hashtable_class_helper.pxi\", line 7081, in pandas._libs.hashtable.PyObjectHashTable.get_item\n  File \"pandas\\\\_libs\\\\hashtable_class_helper.pxi\", line 7089, in pandas._libs.hashtable.PyObjectHashTable.get_item\nKeyError: 'proto'\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"C:\\Users\\miaob\\PycharmProjects\\DataAnalyticsProject\\Lib\\site-packages\\sklearn\\utils\\_indexing.py\", line 364, in _get_column_indices\n    col_idx = all_columns.get_loc(col)\n              ^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\miaob\\PycharmProjects\\DataAnalyticsProject\\Lib\\site-packages\\pandas\\core\\indexes\\base.py\", line 3812, in get_loc\n    raise KeyError(key) from err\nKeyError: 'proto'\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"C:\\Users\\miaob\\PycharmProjects\\DataAnalyticsProject\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\miaob\\PycharmProjects\\DataAnalyticsProject\\Lib\\site-packages\\sklearn\\base.py\", line 1389, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\miaob\\PycharmProjects\\DataAnalyticsProject\\Lib\\site-packages\\sklearn\\pipeline.py\", line 652, in fit\n    Xt = self._fit(X, y, routed_params, raw_params=params)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\miaob\\PycharmProjects\\DataAnalyticsProject\\Lib\\site-packages\\sklearn\\pipeline.py\", line 586, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\miaob\\PycharmProjects\\DataAnalyticsProject\\Lib\\site-packages\\joblib\\memory.py\", line 312, in __call__\n    return self.func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\miaob\\PycharmProjects\\DataAnalyticsProject\\Lib\\site-packages\\sklearn\\pipeline.py\", line 1540, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\miaob\\PycharmProjects\\DataAnalyticsProject\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 319, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\miaob\\PycharmProjects\\DataAnalyticsProject\\Lib\\site-packages\\sklearn\\base.py\", line 1389, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\miaob\\PycharmProjects\\DataAnalyticsProject\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py\", line 992, in fit_transform\n    self._validate_column_callables(X)\n  File \"C:\\Users\\miaob\\PycharmProjects\\DataAnalyticsProject\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py\", line 551, in _validate_column_callables\n    transformer_to_input_indices[name] = _get_column_indices(X, columns)\n                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\miaob\\PycharmProjects\\DataAnalyticsProject\\Lib\\site-packages\\sklearn\\utils\\_indexing.py\", line 372, in _get_column_indices\n    raise ValueError(\"A given column is not a column of the dataframe\") from e\nValueError: A given column is not a column of the dataframe\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "id": "7bcdf539f66957d6",
   "metadata": {},
   "source": [
    "- Performance: 0.9187280941672238 con minmax\n",
    "- Performance: 0.9549626207986386 senza minmax\n",
    "- Accuracy: 0.9745696781095011 Balanced accuracy: 0.8729493259671391 F1 score: 0.9743348139040916"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0bb0d395d0af24e",
   "metadata": {},
   "source": [
    "## Apply Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "id": "9ecffa88485239bf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-16T14:48:51.448593Z",
     "start_time": "2025-01-16T13:56:40.647134Z"
    }
   },
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'rf__n_estimators': [50, 100, 200, 300],  # Number of trees in the forest\n",
    "    'rf__max_depth': [None, 10, 20, 30, 50],  # Maximum depth of the tree\n",
    "    'rf__min_samples_split': [2, 5, 10],  # Minimum number of samples required to split a node\n",
    "    'rf__min_samples_leaf': [1, 2, 4],  # Minimum number of samples required at a leaf node\n",
    "    'rf__max_features': ['sqrt', 'log2', None],  # Number of features to consider when looking for the best split\n",
    "    'rf__bootstrap': [True, False],  # Whether bootstrap samples are used when building trees\n",
    "    'rf__criterion': ['gini', 'entropy', 'log_loss'],  # Split quality measure\n",
    "    # 'class_weight': ['balanced', 'balanced_subsample', None]  # Weights associated with classes\n",
    "}\n",
    "\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        ('ct', ColumnTransformer(\n",
    "            [\n",
    "                (\"cat\", OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1), [c for c in categorical_columns if c in columns_to_keep]),  # Trasforma le colonne categoriche\n",
    "                (\"scale\", RobustScaler(), [n for n in numeric_columns if n in columns_to_keep])  # Normalizza le colonne numeriche\n",
    "            ],\n",
    "            remainder=\"passthrough\"  # Mantieni le altre colonne invariate\n",
    "        )),\n",
    "        ('rf', RandomForestClassifier(random_state=seed, class_weight='balanced'))\n",
    "    ],\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "grid = BayesSearchCV(pipeline, param_grid, cv=ps, n_iter=10, random_state=seed, verbose=2, n_jobs=12, scoring=\"balanced_accuracy\")\n",
    "grid.fit(X, y)\n",
    "\n",
    "print(\"Best parameters:\", grid.best_params_)\n",
    "print(\"Best score:\", grid.best_score_)\n",
    "best_rf = grid.best_estimator_\n",
    "with open(f\"{filepath}/models/rf.save\", \"wb\") as file:\n",
    "    pickle.dump(best_rf, file)\n",
    "\n",
    "y_pred = best_rf.predict(X_val)\n",
    "print(\"Accuracy:\", accuracy_score(y_val, y_pred))\n",
    "print(\"Balanced accuracy:\", balanced_accuracy_score(y_val, y_pred))\n",
    "print(\"F1 score:\", f1_score(y_val, y_pred, average=\"weighted\"))\n",
    "\n",
    "pd.DataFrame(grid.cv_results_)\n",
    "\n",
    "# rf = RandomForestClassifier(random_state=seed, class_weight=\"balanced\", n_jobs=12).fit(X_train, y_train)\n",
    "# y_pred = rf.predict(X_val)\n",
    "# print(\"Accuracy:\", accuracy_score(y_val, y_pred))\n",
    "# print(\"Balanced accuracy:\", balanced_accuracy_score(y_val, y_pred))\n",
    "# print(\"F1 score:\", f1_score(y_val, y_pred, average=\"weighted\"))\n",
    "#\n",
    "# with open(f\"{filepath}/models/rf.save\", \"wb\") as file:\n",
    "#     pickle.dump(rf, file)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[5], line 30\u001B[0m\n\u001B[0;32m     15\u001B[0m pipeline \u001B[38;5;241m=\u001B[39m Pipeline(\n\u001B[0;32m     16\u001B[0m     [\n\u001B[0;32m     17\u001B[0m         (\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mct\u001B[39m\u001B[38;5;124m'\u001B[39m, ColumnTransformer(\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     26\u001B[0m     verbose\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m     27\u001B[0m )\n\u001B[0;32m     29\u001B[0m grid \u001B[38;5;241m=\u001B[39m BayesSearchCV(pipeline, param_grid, cv\u001B[38;5;241m=\u001B[39mps, n_iter\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m10\u001B[39m, random_state\u001B[38;5;241m=\u001B[39mseed, verbose\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m, n_jobs\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m12\u001B[39m, scoring\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbalanced_accuracy\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m---> 30\u001B[0m \u001B[43mgrid\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     32\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mBest parameters:\u001B[39m\u001B[38;5;124m\"\u001B[39m, grid\u001B[38;5;241m.\u001B[39mbest_params_)\n\u001B[0;32m     33\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mBest score:\u001B[39m\u001B[38;5;124m\"\u001B[39m, grid\u001B[38;5;241m.\u001B[39mbest_score_)\n",
      "File \u001B[1;32m~\\PycharmProjects\\DataAnalyticsProject\\Lib\\site-packages\\skopt\\searchcv.py:542\u001B[0m, in \u001B[0;36mBayesSearchCV.fit\u001B[1;34m(self, X, y, groups, callback, **fit_params)\u001B[0m\n\u001B[0;32m    535\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mcallable\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrefit):\n\u001B[0;32m    536\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    537\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mBayesSearchCV doesn\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mt support a callable refit, \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    538\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mas it doesn\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mt define an implicit score to \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    539\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124moptimize\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    540\u001B[0m     )\n\u001B[1;32m--> 542\u001B[0m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgroups\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroups\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mfit_params\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    544\u001B[0m \u001B[38;5;66;03m# BaseSearchCV never ranked train scores,\u001B[39;00m\n\u001B[0;32m    545\u001B[0m \u001B[38;5;66;03m# but apparently we used to ship this (back-compat)\u001B[39;00m\n\u001B[0;32m    546\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mreturn_train_score:\n",
      "File \u001B[1;32m~\\PycharmProjects\\DataAnalyticsProject\\Lib\\site-packages\\sklearn\\base.py:1389\u001B[0m, in \u001B[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001B[1;34m(estimator, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1382\u001B[0m     estimator\u001B[38;5;241m.\u001B[39m_validate_params()\n\u001B[0;32m   1384\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[0;32m   1385\u001B[0m     skip_parameter_validation\u001B[38;5;241m=\u001B[39m(\n\u001B[0;32m   1386\u001B[0m         prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[0;32m   1387\u001B[0m     )\n\u001B[0;32m   1388\u001B[0m ):\n\u001B[1;32m-> 1389\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfit_method\u001B[49m\u001B[43m(\u001B[49m\u001B[43mestimator\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\PycharmProjects\\DataAnalyticsProject\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1023\u001B[0m, in \u001B[0;36mBaseSearchCV.fit\u001B[1;34m(self, X, y, **params)\u001B[0m\n\u001B[0;32m   1017\u001B[0m     results \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_format_results(\n\u001B[0;32m   1018\u001B[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001B[0;32m   1019\u001B[0m     )\n\u001B[0;32m   1021\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m results\n\u001B[1;32m-> 1023\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_run_search\u001B[49m\u001B[43m(\u001B[49m\u001B[43mevaluate_candidates\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1025\u001B[0m \u001B[38;5;66;03m# multimetric is determined here because in the case of a callable\u001B[39;00m\n\u001B[0;32m   1026\u001B[0m \u001B[38;5;66;03m# self.scoring the return type is only known after calling\u001B[39;00m\n\u001B[0;32m   1027\u001B[0m first_test_score \u001B[38;5;241m=\u001B[39m all_out[\u001B[38;5;241m0\u001B[39m][\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtest_scores\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n",
      "File \u001B[1;32m~\\PycharmProjects\\DataAnalyticsProject\\Lib\\site-packages\\skopt\\searchcv.py:599\u001B[0m, in \u001B[0;36mBayesSearchCV._run_search\u001B[1;34m(self, evaluate_candidates)\u001B[0m\n\u001B[0;32m    595\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m n_iter \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m    596\u001B[0m     \u001B[38;5;66;03m# when n_iter < n_points points left for evaluation\u001B[39;00m\n\u001B[0;32m    597\u001B[0m     n_points_adjusted \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mmin\u001B[39m(n_iter, n_points)\n\u001B[1;32m--> 599\u001B[0m     optim_result, score_name \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_step\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    600\u001B[0m \u001B[43m        \u001B[49m\u001B[43msearch_space\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    601\u001B[0m \u001B[43m        \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    602\u001B[0m \u001B[43m        \u001B[49m\u001B[43mscore_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    603\u001B[0m \u001B[43m        \u001B[49m\u001B[43mevaluate_candidates\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    604\u001B[0m \u001B[43m        \u001B[49m\u001B[43mn_points\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mn_points_adjusted\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    605\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    606\u001B[0m     n_iter \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m=\u001B[39m n_points\n\u001B[0;32m    608\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m eval_callbacks(callbacks, optim_result):\n",
      "File \u001B[1;32m~\\PycharmProjects\\DataAnalyticsProject\\Lib\\site-packages\\skopt\\searchcv.py:453\u001B[0m, in \u001B[0;36mBayesSearchCV._step\u001B[1;34m(self, search_space, optimizer, score_name, evaluate_candidates, n_points)\u001B[0m\n\u001B[0;32m    450\u001B[0m \u001B[38;5;66;03m# make lists into dictionaries\u001B[39;00m\n\u001B[0;32m    451\u001B[0m params_dict \u001B[38;5;241m=\u001B[39m [point_asdict(search_space, p) \u001B[38;5;28;01mfor\u001B[39;00m p \u001B[38;5;129;01min\u001B[39;00m params]\n\u001B[1;32m--> 453\u001B[0m all_results \u001B[38;5;241m=\u001B[39m \u001B[43mevaluate_candidates\u001B[49m\u001B[43m(\u001B[49m\u001B[43mparams_dict\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    455\u001B[0m \u001B[38;5;66;03m# if self.scoring is a callable, we have to wait until here\u001B[39;00m\n\u001B[0;32m    456\u001B[0m \u001B[38;5;66;03m# to get the score name\u001B[39;00m\n\u001B[0;32m    457\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m score_name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[1;32m~\\PycharmProjects\\DataAnalyticsProject\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:969\u001B[0m, in \u001B[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001B[1;34m(candidate_params, cv, more_results)\u001B[0m\n\u001B[0;32m    961\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mverbose \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m    962\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\n\u001B[0;32m    963\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFitting \u001B[39m\u001B[38;5;132;01m{0}\u001B[39;00m\u001B[38;5;124m folds for each of \u001B[39m\u001B[38;5;132;01m{1}\u001B[39;00m\u001B[38;5;124m candidates,\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    964\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m totalling \u001B[39m\u001B[38;5;132;01m{2}\u001B[39;00m\u001B[38;5;124m fits\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\n\u001B[0;32m    965\u001B[0m             n_splits, n_candidates, n_candidates \u001B[38;5;241m*\u001B[39m n_splits\n\u001B[0;32m    966\u001B[0m         )\n\u001B[0;32m    967\u001B[0m     )\n\u001B[1;32m--> 969\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[43mparallel\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    970\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdelayed\u001B[49m\u001B[43m(\u001B[49m\u001B[43m_fit_and_score\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    971\u001B[0m \u001B[43m        \u001B[49m\u001B[43mclone\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbase_estimator\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    972\u001B[0m \u001B[43m        \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    973\u001B[0m \u001B[43m        \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    974\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtrain\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    975\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtest\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtest\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    976\u001B[0m \u001B[43m        \u001B[49m\u001B[43mparameters\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mparameters\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    977\u001B[0m \u001B[43m        \u001B[49m\u001B[43msplit_progress\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43msplit_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_splits\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    978\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcandidate_progress\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcand_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_candidates\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    979\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mfit_and_score_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    980\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    981\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mcand_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mparameters\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43msplit_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mproduct\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    982\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43menumerate\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcandidate_params\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    983\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43menumerate\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcv\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msplit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mrouted_params\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msplitter\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msplit\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    984\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    985\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    987\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(out) \u001B[38;5;241m<\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[0;32m    988\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    989\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNo fits were performed. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    990\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mWas the CV iterator empty? \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    991\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mWere there no candidates?\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    992\u001B[0m     )\n",
      "File \u001B[1;32m~\\PycharmProjects\\DataAnalyticsProject\\Lib\\site-packages\\sklearn\\utils\\parallel.py:77\u001B[0m, in \u001B[0;36mParallel.__call__\u001B[1;34m(self, iterable)\u001B[0m\n\u001B[0;32m     72\u001B[0m config \u001B[38;5;241m=\u001B[39m get_config()\n\u001B[0;32m     73\u001B[0m iterable_with_config \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m     74\u001B[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001B[0;32m     75\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m delayed_func, args, kwargs \u001B[38;5;129;01min\u001B[39;00m iterable\n\u001B[0;32m     76\u001B[0m )\n\u001B[1;32m---> 77\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__call__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43miterable_with_config\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\PycharmProjects\\DataAnalyticsProject\\Lib\\site-packages\\joblib\\parallel.py:2007\u001B[0m, in \u001B[0;36mParallel.__call__\u001B[1;34m(self, iterable)\u001B[0m\n\u001B[0;32m   2001\u001B[0m \u001B[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001B[39;00m\n\u001B[0;32m   2002\u001B[0m \u001B[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001B[39;00m\n\u001B[0;32m   2003\u001B[0m \u001B[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001B[39;00m\n\u001B[0;32m   2004\u001B[0m \u001B[38;5;66;03m# dispatch of the tasks to the workers.\u001B[39;00m\n\u001B[0;32m   2005\u001B[0m \u001B[38;5;28mnext\u001B[39m(output)\n\u001B[1;32m-> 2007\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m output \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mreturn_generator \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;43mlist\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43moutput\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\PycharmProjects\\DataAnalyticsProject\\Lib\\site-packages\\joblib\\parallel.py:1650\u001B[0m, in \u001B[0;36mParallel._get_outputs\u001B[1;34m(self, iterator, pre_dispatch)\u001B[0m\n\u001B[0;32m   1647\u001B[0m     \u001B[38;5;28;01myield\u001B[39;00m\n\u001B[0;32m   1649\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backend\u001B[38;5;241m.\u001B[39mretrieval_context():\n\u001B[1;32m-> 1650\u001B[0m         \u001B[38;5;28;01myield from\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_retrieve()\n\u001B[0;32m   1652\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mGeneratorExit\u001B[39;00m:\n\u001B[0;32m   1653\u001B[0m     \u001B[38;5;66;03m# The generator has been garbage collected before being fully\u001B[39;00m\n\u001B[0;32m   1654\u001B[0m     \u001B[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001B[39;00m\n\u001B[0;32m   1655\u001B[0m     \u001B[38;5;66;03m# the user if necessary.\u001B[39;00m\n\u001B[0;32m   1656\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_exception \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "File \u001B[1;32m~\\PycharmProjects\\DataAnalyticsProject\\Lib\\site-packages\\joblib\\parallel.py:1762\u001B[0m, in \u001B[0;36mParallel._retrieve\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1757\u001B[0m \u001B[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001B[39;00m\n\u001B[0;32m   1758\u001B[0m \u001B[38;5;66;03m# async callbacks to progress.\u001B[39;00m\n\u001B[0;32m   1759\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m ((\u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jobs) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m) \u001B[38;5;129;01mor\u001B[39;00m\n\u001B[0;32m   1760\u001B[0m     (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jobs[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mget_status(\n\u001B[0;32m   1761\u001B[0m         timeout\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtimeout) \u001B[38;5;241m==\u001B[39m TASK_PENDING)):\n\u001B[1;32m-> 1762\u001B[0m     \u001B[43mtime\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msleep\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m0.01\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1763\u001B[0m     \u001B[38;5;28;01mcontinue\u001B[39;00m\n\u001B[0;32m   1765\u001B[0m \u001B[38;5;66;03m# We need to be careful: the job list can be filling up as\u001B[39;00m\n\u001B[0;32m   1766\u001B[0m \u001B[38;5;66;03m# we empty it and Python list are not thread-safe by\u001B[39;00m\n\u001B[0;32m   1767\u001B[0m \u001B[38;5;66;03m# default hence the use of the lock\u001B[39;00m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "id": "521b7fab",
   "metadata": {},
   "source": [
    "0.9989123986553292 senza scaling\n",
    "\n",
    "0.9990112715048448 con scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d48c37",
   "metadata": {},
   "source": [
    "## Apply Support Vector Classifier with HP tuning"
   ]
  },
  {
   "cell_type": "code",
   "id": "b5506638",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-15T14:00:20.667296Z",
     "start_time": "2025-01-15T12:53:12.034975Z"
    }
   },
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "# param_grid = {'C': [0.1, 1, 10, 100, 1000],\n",
    "#               'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
    "#               'kernel': ['rbf']}\n",
    "\n",
    "param_grid = {\n",
    "    'alpha': [0.0001, 0.001, 0.01, 0.1, 1],\n",
    "    'loss': [\"hinge\"],  # \"log_loss\", \"modified_huber\", \"squared_hinge\", \"perceptron\"\n",
    "    'penalty': [\"l2\", \"l1\", \"elasticnet\"],\n",
    "    'learning_rate': [\"optimal\", \"invscaling\", \"adaptive\"],\n",
    "    'eta0': [0.01, 0.1, 1, 10],\n",
    "    'power_t': [0.1, 0.5, 1, 5],\n",
    "    'average': [True, False]\n",
    "}\n",
    "\n",
    "# param_grid = {\n",
    "#     'C': (0.1, 100, 'log-uniform'),\n",
    "#     'gamma': (0.001, 10, 'log-uniform'),\n",
    "#     'kernel': [\"rbf\"]\n",
    "# }\n",
    "\n",
    "grid = BayesSearchCV(\n",
    "    SGDClassifier(random_state=seed, class_weight=\"balanced\", verbose=0, n_jobs=12),\n",
    "    param_grid,\n",
    "    n_iter=10,  # Numero massimo di iterazioni\n",
    "    cv=ps,\n",
    "    verbose=1,\n",
    "    random_state=seed,\n",
    "    scoring=\"balanced_accuracy\"\n",
    ")\n",
    "grid.fit(X, y)\n",
    "\n",
    "print(\"Best parameters:\", grid.best_params_)\n",
    "print(\"Best score:\", grid.best_score_)\n",
    "best_svm = grid.best_estimator_\n",
    "with open(f\"{filepath}/models/svm.save\", \"wb\") as file:\n",
    "    pickle.dump(best_svm, file)\n",
    "y_pred = best_svm.predict(X_val)\n",
    "print(\"Accuracy:\", accuracy_score(y_val, y_pred))\n",
    "print(\"Balanced accuracy:\", balanced_accuracy_score(y_val, y_pred))\n",
    "print(\"F1 score:\", f1_score(y_val, y_pred, average=\"weighted\"))\n",
    "\n",
    "pd.DataFrame(grid.cv_results_)\n",
    "\n",
    "# svm = SVC(random_state=seed, class_weight=\"balanced\", verbose=1, C=100).fit(X_train[:10000], y_train[:10000])\n",
    "# svm = SGDClassifier(random_state=seed, class_weight=\"balanced\", verbose=2, n_jobs=12).fit(X_train, y_train)\n",
    "# y_pred = svm.predict(X_val)\n",
    "# print(\"Accuracy:\", accuracy_score(y_val, y_pred))\n",
    "# print(\"Balanced accuracy:\", balanced_accuracy_score(y_val, y_pred))\n",
    "# print(\"F1 score:\", f1_score(y_val, y_pred, average=\"weighted\"))\n",
    "#\n",
    "# with open(f\"{filepath}/models/svm.save\", \"wb\") as file:\n",
    "#     pickle.dump(svm, file)\n",
    "\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\miaob\\PycharmProjects\\DataAnalyticsProject\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:738: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\miaob\\PycharmProjects\\DataAnalyticsProject\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:738: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\miaob\\PycharmProjects\\DataAnalyticsProject\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:738: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\miaob\\PycharmProjects\\DataAnalyticsProject\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:738: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\miaob\\PycharmProjects\\DataAnalyticsProject\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:738: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\miaob\\PycharmProjects\\DataAnalyticsProject\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:738: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\miaob\\PycharmProjects\\DataAnalyticsProject\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:738: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\miaob\\PycharmProjects\\DataAnalyticsProject\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:738: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\miaob\\PycharmProjects\\DataAnalyticsProject\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:738: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\miaob\\PycharmProjects\\DataAnalyticsProject\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:738: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Best parameters: OrderedDict({'alpha': 0.0001, 'average': False, 'eta0': 1, 'learning_rate': 'optimal', 'loss': 'modified_huber', 'penalty': 'l2', 'power_t': 0.5})\n",
      "Best score: 0.6896217820090957\n",
      "Accuracy: 0.6394372589062854\n",
      "Balanced accuracy: 0.5549949558990029\n",
      "F1 score: 0.6872223688164277\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  param_alpha  \\\n",
       "0     265.175159     19.581271         0.010093        0.000831       0.0100   \n",
       "1      12.501902      0.930198         0.010171        0.001094       1.0000   \n",
       "2       3.485439      0.557518         0.009635        0.000862       0.0100   \n",
       "3      28.110854      1.598656         0.009873        0.001310       1.0000   \n",
       "4      24.963539      2.173775         0.011439        0.003067       0.1000   \n",
       "5       3.406497      3.480001         0.011394        0.002534       0.1000   \n",
       "6      20.167309      1.075677         0.009573        0.000723       0.1000   \n",
       "7      18.337396      1.312130         0.009704        0.000781       0.0100   \n",
       "8      17.128403      1.893942         0.009500        0.001284       1.0000   \n",
       "9       8.357687      0.781089         0.009604        0.000704       0.0001   \n",
       "\n",
       "   param_average  param_eta0 param_learning_rate      param_loss  \\\n",
       "0          False       10.00             optimal   squared_hinge   \n",
       "1          False        0.10            adaptive      perceptron   \n",
       "2          False        0.01          invscaling           hinge   \n",
       "3           True        1.00            adaptive  modified_huber   \n",
       "4           True        1.00            adaptive      perceptron   \n",
       "5          False        0.01             optimal      perceptron   \n",
       "6          False        0.10            adaptive  modified_huber   \n",
       "7          False        0.10            adaptive        log_loss   \n",
       "8          False       10.00          invscaling        log_loss   \n",
       "9          False        1.00             optimal  modified_huber   \n",
       "\n",
       "  param_penalty  ...  split3_test_score split4_test_score  split5_test_score  \\\n",
       "0            l1  ...           0.353302          0.229067           0.207981   \n",
       "1            l2  ...           0.697267          0.529499           0.661853   \n",
       "2            l1  ...           0.619842          0.695728           0.617492   \n",
       "3            l2  ...           0.002123          0.003096           0.002869   \n",
       "4    elasticnet  ...           0.030763          0.034134           0.031136   \n",
       "5            l1  ...           0.001572          0.031217           0.020860   \n",
       "6            l1  ...           0.549029          0.566064           0.564573   \n",
       "7            l2  ...           0.645402          0.643684           0.640912   \n",
       "8            l2  ...           0.132500          0.024571           0.023891   \n",
       "9            l2  ...           0.692356          0.655289           0.728581   \n",
       "\n",
       "   split6_test_score  split7_test_score  split8_test_score  split9_test_score  \\\n",
       "0           0.266864           0.480048           0.618529           0.191627   \n",
       "1           0.717868           0.709812           0.591640           0.651383   \n",
       "2           0.656893           0.573519           0.625531           0.609339   \n",
       "3           0.002626           0.002593           0.002804           0.002755   \n",
       "4           0.033048           0.030649           0.029774           0.035949   \n",
       "5           0.001572           0.001556           0.019984           0.001556   \n",
       "6           0.560261           0.548543           0.557571           0.527424   \n",
       "7           0.642744           0.647444           0.639308           0.639729   \n",
       "8           0.181546           0.024588           0.001021           0.355927   \n",
       "9           0.635628           0.744530           0.703297           0.583601   \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  \n",
       "0         0.341619        0.133579                6  \n",
       "1         0.629937        0.067504                3  \n",
       "2         0.594834        0.061251                4  \n",
       "3         0.002551        0.000564               10  \n",
       "4         0.031991        0.001989                9  \n",
       "5         0.047422        0.099491                8  \n",
       "6         0.555352        0.011657                5  \n",
       "7         0.643170        0.002671                2  \n",
       "8         0.130368        0.118101                7  \n",
       "9         0.689622        0.048224                1  \n",
       "\n",
       "[10 rows x 25 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_alpha</th>\n",
       "      <th>param_average</th>\n",
       "      <th>param_eta0</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_loss</th>\n",
       "      <th>param_penalty</th>\n",
       "      <th>...</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>265.175159</td>\n",
       "      <td>19.581271</td>\n",
       "      <td>0.010093</td>\n",
       "      <td>0.000831</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>False</td>\n",
       "      <td>10.00</td>\n",
       "      <td>optimal</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.353302</td>\n",
       "      <td>0.229067</td>\n",
       "      <td>0.207981</td>\n",
       "      <td>0.266864</td>\n",
       "      <td>0.480048</td>\n",
       "      <td>0.618529</td>\n",
       "      <td>0.191627</td>\n",
       "      <td>0.341619</td>\n",
       "      <td>0.133579</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12.501902</td>\n",
       "      <td>0.930198</td>\n",
       "      <td>0.010171</td>\n",
       "      <td>0.001094</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>False</td>\n",
       "      <td>0.10</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>perceptron</td>\n",
       "      <td>l2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.697267</td>\n",
       "      <td>0.529499</td>\n",
       "      <td>0.661853</td>\n",
       "      <td>0.717868</td>\n",
       "      <td>0.709812</td>\n",
       "      <td>0.591640</td>\n",
       "      <td>0.651383</td>\n",
       "      <td>0.629937</td>\n",
       "      <td>0.067504</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.485439</td>\n",
       "      <td>0.557518</td>\n",
       "      <td>0.009635</td>\n",
       "      <td>0.000862</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>False</td>\n",
       "      <td>0.01</td>\n",
       "      <td>invscaling</td>\n",
       "      <td>hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.619842</td>\n",
       "      <td>0.695728</td>\n",
       "      <td>0.617492</td>\n",
       "      <td>0.656893</td>\n",
       "      <td>0.573519</td>\n",
       "      <td>0.625531</td>\n",
       "      <td>0.609339</td>\n",
       "      <td>0.594834</td>\n",
       "      <td>0.061251</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28.110854</td>\n",
       "      <td>1.598656</td>\n",
       "      <td>0.009873</td>\n",
       "      <td>0.001310</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>True</td>\n",
       "      <td>1.00</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>modified_huber</td>\n",
       "      <td>l2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002123</td>\n",
       "      <td>0.003096</td>\n",
       "      <td>0.002869</td>\n",
       "      <td>0.002626</td>\n",
       "      <td>0.002593</td>\n",
       "      <td>0.002804</td>\n",
       "      <td>0.002755</td>\n",
       "      <td>0.002551</td>\n",
       "      <td>0.000564</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24.963539</td>\n",
       "      <td>2.173775</td>\n",
       "      <td>0.011439</td>\n",
       "      <td>0.003067</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>True</td>\n",
       "      <td>1.00</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>perceptron</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>...</td>\n",
       "      <td>0.030763</td>\n",
       "      <td>0.034134</td>\n",
       "      <td>0.031136</td>\n",
       "      <td>0.033048</td>\n",
       "      <td>0.030649</td>\n",
       "      <td>0.029774</td>\n",
       "      <td>0.035949</td>\n",
       "      <td>0.031991</td>\n",
       "      <td>0.001989</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3.406497</td>\n",
       "      <td>3.480001</td>\n",
       "      <td>0.011394</td>\n",
       "      <td>0.002534</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>False</td>\n",
       "      <td>0.01</td>\n",
       "      <td>optimal</td>\n",
       "      <td>perceptron</td>\n",
       "      <td>l1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001572</td>\n",
       "      <td>0.031217</td>\n",
       "      <td>0.020860</td>\n",
       "      <td>0.001572</td>\n",
       "      <td>0.001556</td>\n",
       "      <td>0.019984</td>\n",
       "      <td>0.001556</td>\n",
       "      <td>0.047422</td>\n",
       "      <td>0.099491</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>20.167309</td>\n",
       "      <td>1.075677</td>\n",
       "      <td>0.009573</td>\n",
       "      <td>0.000723</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>False</td>\n",
       "      <td>0.10</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>modified_huber</td>\n",
       "      <td>l1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.549029</td>\n",
       "      <td>0.566064</td>\n",
       "      <td>0.564573</td>\n",
       "      <td>0.560261</td>\n",
       "      <td>0.548543</td>\n",
       "      <td>0.557571</td>\n",
       "      <td>0.527424</td>\n",
       "      <td>0.555352</td>\n",
       "      <td>0.011657</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>18.337396</td>\n",
       "      <td>1.312130</td>\n",
       "      <td>0.009704</td>\n",
       "      <td>0.000781</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>False</td>\n",
       "      <td>0.10</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>l2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.645402</td>\n",
       "      <td>0.643684</td>\n",
       "      <td>0.640912</td>\n",
       "      <td>0.642744</td>\n",
       "      <td>0.647444</td>\n",
       "      <td>0.639308</td>\n",
       "      <td>0.639729</td>\n",
       "      <td>0.643170</td>\n",
       "      <td>0.002671</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>17.128403</td>\n",
       "      <td>1.893942</td>\n",
       "      <td>0.009500</td>\n",
       "      <td>0.001284</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>False</td>\n",
       "      <td>10.00</td>\n",
       "      <td>invscaling</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>l2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.132500</td>\n",
       "      <td>0.024571</td>\n",
       "      <td>0.023891</td>\n",
       "      <td>0.181546</td>\n",
       "      <td>0.024588</td>\n",
       "      <td>0.001021</td>\n",
       "      <td>0.355927</td>\n",
       "      <td>0.130368</td>\n",
       "      <td>0.118101</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8.357687</td>\n",
       "      <td>0.781089</td>\n",
       "      <td>0.009604</td>\n",
       "      <td>0.000704</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>False</td>\n",
       "      <td>1.00</td>\n",
       "      <td>optimal</td>\n",
       "      <td>modified_huber</td>\n",
       "      <td>l2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.692356</td>\n",
       "      <td>0.655289</td>\n",
       "      <td>0.728581</td>\n",
       "      <td>0.635628</td>\n",
       "      <td>0.744530</td>\n",
       "      <td>0.703297</td>\n",
       "      <td>0.583601</td>\n",
       "      <td>0.689622</td>\n",
       "      <td>0.048224</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 25 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
